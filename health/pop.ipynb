{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, requests, zipfile, StringIO, pandas as pd, json, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data source WHO Mortality database\n",
    "#http://www.who.int/healthinfo/statistics/mortality_rawdata/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you might want to skip this cell, depending on your system configuration\n",
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read country codes\n",
    "z = zipfile.ZipFile('country_codes.zip') \n",
    "cc = pd.read_csv(z.open('country_codes'),low_memory=False).set_index('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def part1():\n",
    "    #read data\n",
    "    z = zipfile.ZipFile('morticd10_part1.zip') \n",
    "    df = pd.read_csv(z.open('Morticd10_part1'),low_memory=False)\n",
    "\n",
    "    #filter out non-country (subdivision) data\n",
    "    df = df[np.isnan(df['Admin1'])]\n",
    "    df = df[np.isnan(df['SubDiv'])]\n",
    "    df = df.drop(['Admin1','SubDiv'],axis=1)\n",
    "\n",
    "    #filter out data after ICD10 classification\n",
    "    df = df[df['List']=='104']\n",
    "    df = df.drop(['List'],axis=1)\n",
    "\n",
    "    #filter out non-detailed mortality\n",
    "    #df = df[df['Frmat']==1]\n",
    "    #df = df.drop(['Frmat'],axis=1)\n",
    "\n",
    "    #filter out detailed infant mortality\n",
    "    #df = df[df['IM_Frmat']==8]\n",
    "    df = df.drop(['IM_Frmat'],axis=1)\n",
    "\n",
    "    df=df.drop(['IM_Deaths1'],axis=1).\\\n",
    "        drop(['IM_Deaths2'],axis=1).\\\n",
    "        drop(['IM_Deaths3'],axis=1).\\\n",
    "        drop(['IM_Deaths4'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def part2():\n",
    "    #read data\n",
    "    z = zipfile.ZipFile('morticd10_part2.zip') \n",
    "    df2 = pd.read_csv(z.open('Morticd10_part2'),low_memory=False)\n",
    "\n",
    "    #filter out non-country (subdivision) data\n",
    "    df2 = df2[np.isnan(df2['Admin1'])]\n",
    "    df2 = df2[df2['SubDiv']!='A30']\n",
    "    df2 = df2.drop(['Admin1','SubDiv'],axis=1)\n",
    "\n",
    "    #filter out data after ICD10 classification\n",
    "    df2 = df2[df2['List']=='104']\n",
    "    df2 = df2.drop(['List'],axis=1)\n",
    "\n",
    "    #filter out non-detailed mortality\n",
    "    #df2 = df2[df2['Frmat']==1]\n",
    "    #df2 = df2.drop(['Frmat'],axis=1)\n",
    "\n",
    "    #filter out detailed infant mortality\n",
    "    #df2 = df2[df2['IM_Frmat']==8]\n",
    "    df2 = df2.drop(['IM_Frmat'],axis=1)\n",
    "\n",
    "    df2=df2.drop(['IM_Deaths1'],axis=1).\\\n",
    "        drop(['IM_Deaths2'],axis=1).\\\n",
    "        drop(['IM_Deaths3'],axis=1).\\\n",
    "        drop(['IM_Deaths4'],axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(index):\n",
    "    #merge the two dataframes\n",
    "    df = pd.concat([part1(),part2()])\n",
    "    #set index\n",
    "    df = df.set_index(index)\n",
    "    #set column names\n",
    "    df.columns=['Deaths1']+range(5)+list(np.arange(1,20)*5)+['Deaths26']\n",
    "    #normalize data\n",
    "    dg0=df.loc[0].copy()\n",
    "    dg1=df.loc[1].copy()\n",
    "    dg1[90]=df.loc[1][85]*3/10.0\n",
    "    dg1[95]=df.loc[1][85]*1/10.0\n",
    "    dg1[85]=df.loc[2][85]*6/10.0\n",
    "    dg2=df.loc[2].copy()\n",
    "    dg2[90]=df.loc[2][85]*3/10.0\n",
    "    dg2[95]=df.loc[2][85]*1/10.0\n",
    "    dg2[85]=df.loc[2][85]*6/10.0\n",
    "    dg2[2]=df.loc[2][1]*1/4.0\n",
    "    dg2[3]=df.loc[2][1]*1/4.0\n",
    "    dg2[4]=df.loc[2][1]*1/4.0\n",
    "    dg2[1]=df.loc[2][1]*1/4.0\n",
    "    return pd.concat([dg0,dg1,dg2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load df for processing\n",
    "df=load_df(['Frmat','Country','Year','Cause','Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Andorra                  20\n",
       "United Arab Emirates    784\n",
       "Afghanistan               4\n",
       "Antigua and Barbuda      28\n",
       "Anguilla                660\n",
       "Name: ISONUM, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries=pd.read_html('http://www.geonames.org/countries/',header=0)[1]\n",
    "countries.columns=['ISO2','ISO3','ISONUM','FIPS','Country','Capital','Area','Population','Continent']\n",
    "countries.set_index('Country',drop=True,inplace=True)\n",
    "countries=countries['ISONUM']\n",
    "countries.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch={}\n",
    "for i in countries.index:\n",
    "    try: ch[countries.loc[i]]=i\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ccv(f):\n",
    "    if f=='Russian Federation':return 'Russia'\n",
    "    elif f=='Brunei Darussalam':return 'Brunei'\n",
    "    elif f=='Reunion':return u'R\\xc3\\xa9union'\n",
    "    elif f=='Saint Vincent and Grenadines':return 'Saint Vincent and the Grenadines'\n",
    "    elif f=='United States of America':return 'United States'\n",
    "    elif f=='Virgin Islands (USA)':return 'U.S. Virgin Islands'\n",
    "    elif f=='Hong Kong SAR':return 'Hong Kong'\n",
    "    elif f=='Republic of Korea':return 'South Korea'\n",
    "    elif f=='Republic of Moldova':return 'Moldova'\n",
    "    elif f=='Serbia and Montenegro, Former':return 'Serbia'\n",
    "    else: return f\n",
    "\n",
    "todrop=set()\n",
    "for i in list(df.index.levels[0]):\n",
    "    if ccv(cc.loc[i][0]) not in list(countries.index):\n",
    "        print cc.loc[i][0]\n",
    "        todrop.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#icd=pd.read_excel('icd.xlsx').set_index('code')\n",
    "icd=pd.read_excel('icd_hun.xlsx',).set_index('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "igroup=[1000,\n",
    "1001,\n",
    "1026,\n",
    "1048,\n",
    "1051,\n",
    "1055,\n",
    "1058,\n",
    "1062,\n",
    "1063,\n",
    "1064,\n",
    "1072,\n",
    "1078,\n",
    "1082,\n",
    "1083,\n",
    "1084,\n",
    "1087,\n",
    "1092,\n",
    "1093,\n",
    "1094,\n",
    "1095,\n",
    "2000]#protector dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub': {}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create hierarchy of diseases\n",
    "\n",
    "#numbers first\n",
    "hierarchy={}\n",
    "currenti=0\n",
    "for k in icd.T.iteritems():\n",
    "    i=k[0]\n",
    "    if i>igroup[currenti]: currenti+=1\n",
    "    if igroup[currenti] not in hierarchy:\n",
    "        hierarchy[igroup[currenti]]={'sub':{}}\n",
    "    if i<igroup[currenti]:\n",
    "        hierarchy[igroup[currenti-1]]['sub'][str(i)]={}\n",
    "    if i not in hierarchy:hierarchy[i]={'parent':str(igroup[currenti-1])}\n",
    "    hierarchy[i]['name']=k[1][1]\n",
    "    hierarchy[i]['hun']=k[1][2]\n",
    "        \n",
    "hierarchy.pop(2000); #pop out protector dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stringifiy all dictionary entries for JSON\n",
    "for k in hierarchy.keys():\n",
    "    hierarchy[str(k)]=hierarchy[k]\n",
    "    hierarchy.pop(k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#characters after\n",
    "for i in icd.T.iteritems():\n",
    "    try: \n",
    "        if np.isnan(i[1][0]): \n",
    "            hierarchy['AAA']={'parent':'1000'}\n",
    "            #hierarchy[1000]['sub']['AAA']={'m':0,'f':0}\n",
    "            hierarchy['1000']['sub']['AAA']={}\n",
    "    except: \n",
    "        #only sub-groups, no major groups \n",
    "        a=False\n",
    "        b=False\n",
    "        w=str(i[0])\n",
    "        if 'sub' in hierarchy[w]:\n",
    "            if hierarchy[w]['sub']=={}: a=True\n",
    "        if 'parent' in hierarchy[w]:\n",
    "            b=True\n",
    "        if (a or b):\n",
    "            groups=i[1][0].split(',')\n",
    "            for g in groups:\n",
    "                if '-' in g:\n",
    "                    first=g[:g.find('-')].strip()\n",
    "                    second=g[g.find('-')+1:].strip()\n",
    "                    if first[:1]==second[:1]:\n",
    "                        for k in range(int(first[1:]),int(second[1:])+1):\n",
    "                            disease = first[:1]+str(k).zfill(2)\n",
    "                            hierarchy[disease]={'parent':w}\n",
    "                    else: \n",
    "                        #character-break (A-B, X-Y etc) of category\n",
    "                        for k in range(int(first[1:]),100):\n",
    "                            disease = first[:1]+str(k).zfill(2)\n",
    "                            hierarchy[disease]={'parent':w}\n",
    "                        for k in range(1,int(second[1:])+1):\n",
    "                            disease = second[:1]+str(k).zfill(2)\n",
    "                            hierarchy[disease]={'parent':w}\n",
    "                else:\n",
    "                    hierarchy[g.strip()]={'parent':w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill up the sub-hierarchies\n",
    "for i in hierarchy:\n",
    "    if 'parent' in hierarchy[i]:\n",
    "        parent1=hierarchy[i]['parent']\n",
    "        if 'parent' in hierarchy[parent1]:\n",
    "            parent2=hierarchy[parent1]['parent']\n",
    "            if 'sub' not in hierarchy[parent2]['sub'][parent1]:hierarchy[parent2]['sub'][parent1]['sub']={}\n",
    "            hierarchy[parent2]['sub'][parent1]['sub'][i]={}\n",
    "        else: \n",
    "            hierarchy[parent1]['sub'][i]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group_getter\n",
    "def get_group(i):\n",
    "    if 'parent' in hierarchy[i]:\n",
    "        parent1=hierarchy[i]['parent']\n",
    "        if 'parent' in hierarchy[parent1]:\n",
    "            return hierarchy[parent1]['parent']\n",
    "        else: return parent1\n",
    "    else: return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parent_getter\n",
    "def get_parent(i):\n",
    "    if 'parent' in hierarchy[i]:\n",
    "        return hierarchy[i]['parent']\n",
    "    else: return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read data for population\n",
    "z = zipfile.ZipFile('Pop.zip') \n",
    "pop = pd.read_csv(z.open('pop'),low_memory=False)\n",
    "pop = pop.set_index(['Frmat','Country','Year','Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter out non-country (subdivision) data\n",
    "pop = pop[np.isnan(pop['Admin1'])]\n",
    "pop = pop[pop['SubDiv']!='A30']\n",
    "pop = pop[pop['SubDiv']!='A20']\n",
    "pop = pop[pop['SubDiv']!='A35']\n",
    "pop = pop[pop['SubDiv']!='A41']\n",
    "pop = pop[pop['SubDiv']!='A51']\n",
    "pop = pop[pop['SubDiv']!='A70']\n",
    "pop = pop.drop(['Admin1','SubDiv'],axis=1)\n",
    "pop = pop.drop(['Pop1','Pop26','Lb'],axis=1)\n",
    "pop.columns=range(5)+list(np.arange(1,20)*5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize formatting\n",
    "dr0=pop.loc[0].copy()\n",
    "dr1=pop.loc[1].copy()\n",
    "dr1[90]=pop.loc[1][85]*3/10.0\n",
    "dr1[95]=pop.loc[1][85]*1/10.0\n",
    "dr1[85]=pop.loc[1][85]*6/10.0\n",
    "dr2=pop.loc[2].copy()\n",
    "dr2[90]=pop.loc[2][85]*3/10.0\n",
    "dr2[95]=pop.loc[2][85]*1/10.0\n",
    "dr2[85]=pop.loc[2][85]*6/10.0\n",
    "dr2[2]=pop.loc[2][1]*1/4.0\n",
    "dr2[3]=pop.loc[2][1]*1/4.0\n",
    "dr2[4]=pop.loc[2][1]*1/4.0\n",
    "dr2[1]=pop.loc[2][1]*1/4.0\n",
    "dr3=pop.loc[3].copy()\n",
    "dr3[90]=pop.loc[3][75]*1/121.0\n",
    "dr3[95]=pop.loc[3][75]*3/121.0\n",
    "dr3[85]=pop.loc[3][75]*9/121.0\n",
    "dr3[80]=pop.loc[3][75]*27/121.0\n",
    "dr3[75]=pop.loc[3][75]*81/121.0\n",
    "dr4=pop.loc[4].copy()\n",
    "dr4[90]=pop.loc[4][75]*1/121.0\n",
    "dr4[95]=pop.loc[4][75]*3/121.0\n",
    "dr4[85]=pop.loc[4][75]*9/121.0\n",
    "dr4[80]=pop.loc[4][75]*27/121.0\n",
    "dr4[75]=pop.loc[4][75]*81/121.0\n",
    "dr4[2]=pop.loc[4][1]*1/4.0\n",
    "dr4[3]=pop.loc[4][1]*1/4.0\n",
    "dr4[4]=pop.loc[4][1]*1/4.0\n",
    "dr4[1]=pop.loc[4][1]*1/4.0\n",
    "dr5=pop.loc[5].copy()\n",
    "dr5[90]=pop.loc[5][70]*1/364.0\n",
    "dr5[95]=pop.loc[5][70]*3/364.0\n",
    "dr5[85]=pop.loc[5][70]*9/364.0\n",
    "dr5[80]=pop.loc[5][70]*27/364.0\n",
    "dr5[75]=pop.loc[5][70]*81/364.0\n",
    "dr5[70]=pop.loc[5][70]*243/364.0\n",
    "dr5[2]=pop.loc[5][1]*1/4.0\n",
    "dr5[3]=pop.loc[5][1]*1/4.0\n",
    "dr5[4]=pop.loc[5][1]*1/4.0\n",
    "dr5[1]=pop.loc[5][1]*1/4.0\n",
    "dr6=pop.loc[6].copy()\n",
    "dr6[90]=pop.loc[6][65]*1/1093.0\n",
    "dr6[95]=pop.loc[6][65]*3/1093.0\n",
    "dr6[85]=pop.loc[6][65]*9/1093.0\n",
    "dr6[80]=pop.loc[6][65]*27/1093.0\n",
    "dr6[75]=pop.loc[6][65]*81/1093.0\n",
    "dr6[70]=pop.loc[6][65]*243/1093.0\n",
    "dr6[65]=pop.loc[6][65]*729/1093.0\n",
    "dr6[2]=pop.loc[6][1]*1/4.0\n",
    "dr6[3]=pop.loc[6][1]*1/4.0\n",
    "dr6[4]=pop.loc[6][1]*1/4.0\n",
    "dr6[1]=pop.loc[6][1]*1/4.0\n",
    "dr7=pop.loc[7].copy()\n",
    "dr7[2]=pop.loc[7][1]*1/4.0\n",
    "dr7[3]=pop.loc[7][1]*1/4.0\n",
    "dr7[4]=pop.loc[7][1]*1/4.0\n",
    "dr7[1]=pop.loc[7][1]*1/4.0\n",
    "dr7[10]=(pop.loc[7][5]+pop.loc[7][15])/4.0\n",
    "dr7[20]=(pop.loc[7][15]+pop.loc[7][25])/4.0\n",
    "dr7[30]=(pop.loc[7][25]+pop.loc[7][35])/4.0\n",
    "dr7[40]=(pop.loc[7][35]+pop.loc[7][45])/4.0\n",
    "dr7[50]=(pop.loc[7][45]+pop.loc[7][55])/4.0\n",
    "dr7[60]=(pop.loc[7][55]+pop.loc[7][65])/4.0\n",
    "dr7[70]=(pop.loc[7][65])/2.0\n",
    "dr7[5]=pop.loc[7][5]/2.0\n",
    "dr7[15]=pop.loc[7][15]/2.0\n",
    "dr7[25]=pop.loc[7][25]/2.0\n",
    "dr7[35]=pop.loc[7][35]/2.0\n",
    "dr7[45]=pop.loc[7][45]/2.0\n",
    "dr7[55]=pop.loc[7][55]/2.0\n",
    "dr7[65]=pop.loc[7][65]/2.0\n",
    "dr7[90]=pop.loc[7][75]*1/121.0\n",
    "dr7[95]=pop.loc[7][75]*3/121.0\n",
    "dr7[85]=pop.loc[7][75]*9/121.0\n",
    "dr7[80]=pop.loc[7][75]*27/121.0\n",
    "dr7[75]=pop.loc[7][75]*81/121.0\n",
    "dr8=pop.loc[8].copy()\n",
    "dr8[2]=pop.loc[8][1]*1/4.0\n",
    "dr8[3]=pop.loc[8][1]*1/4.0\n",
    "dr8[4]=pop.loc[8][1]*1/4.0\n",
    "dr8[1]=pop.loc[8][1]*1/4.0\n",
    "dr8[10]=(pop.loc[8][5]+pop.loc[7][15])/4.0\n",
    "dr8[20]=(pop.loc[8][15]+pop.loc[7][25])/4.0\n",
    "dr8[30]=(pop.loc[8][25]+pop.loc[7][35])/4.0\n",
    "dr8[40]=(pop.loc[8][35]+pop.loc[7][45])/4.0\n",
    "dr8[50]=(pop.loc[8][45]+pop.loc[7][55])/4.0\n",
    "dr8[60]=(pop.loc[8][55])/2.0\n",
    "dr8[5]=pop.loc[8][5]/2.0\n",
    "dr8[15]=pop.loc[8][15]/2.0\n",
    "dr8[25]=pop.loc[8][25]/2.0\n",
    "dr8[35]=pop.loc[8][35]/2.0\n",
    "dr8[45]=pop.loc[8][45]/2.0\n",
    "dr8[55]=pop.loc[8][55]/2.0\n",
    "dr8[90]=pop.loc[8][65]*1/1093.0\n",
    "dr8[95]=pop.loc[8][65]*3/1093.0\n",
    "dr8[85]=pop.loc[8][65]*9/1093.0\n",
    "dr8[80]=pop.loc[8][65]*27/1093.0\n",
    "dr8[75]=pop.loc[8][65]*81/1093.0\n",
    "dr8[70]=pop.loc[8][65]*243/1093.0\n",
    "dr8[65]=pop.loc[8][65]*729/1093.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop=pd.concat([dr0,dr1,dr2,dr3,dr4,dr5,dr6,dr7,dr8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ccw(c):\n",
    "    if c=='Sao Tome and Principe':return u'S\\xc3\\xa3o Tom\\xc3\\xa9 and Pr\\xc3\\xadncipe'\n",
    "    elif c=='Falkland Islands (Malvinas)':return 'Falkland Islands'\n",
    "    elif c=='China: Province of Taiwan only':return 'Taiwan'\n",
    "    elif c=='Iran (Islamic Republic of)':return 'Iran'\n",
    "    elif c=='Syrian Arab Republic':return 'Syria'\n",
    "    elif c=='TFYR Macedonia':return 'Macedonia' \n",
    "    else:return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp={'007':{}} #007 for world\n",
    "for p in pop.T.iteritems():\n",
    "    try:\n",
    "        country_id=countries.loc[ccw(ccv(cc.loc[p[0][0]][0]))]\n",
    "        if str(country_id) not in pp: pp[str(country_id)]={}\n",
    "        if p[0][1]>1985: #no mortality data before that\n",
    "            if str(p[0][1]) not in pp[str(country_id)]:pp[str(country_id)][str(p[0][1])]={}\n",
    "            if str(p[0][1]) not in pp['007']:pp['007'][str(p[0][1])]={}\n",
    "            if p[0][2]>1:g='f'\n",
    "            else: g='m'\n",
    "            if g not in pp[str(country_id)][str(p[0][1])]:pp[str(country_id)][str(p[0][1])][g]={}\n",
    "            if g not in pp['007'][str(p[0][1])]:pp['007'][str(p[0][1])][g]={}\n",
    "            for j in pop.columns:\n",
    "                v=p[1][j]\n",
    "                if np.isnan(p[1][j]):v=0\n",
    "                pp[str(country_id)][str(p[0][1])][g][str(j)]=str(v)\n",
    "                if str(j) not in pp['007'][str(p[0][1])][g]:pp['007'][str(p[0][1])][g][str(j)]=0\n",
    "                pp['007'][str(p[0][1])][g][str(j)]+=v\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to str\n",
    "for y in pp['007']:\n",
    "    for g in pp['007'][y]:\n",
    "        for a in pp['007'][y][g]:\n",
    "            pp['007'][y][g][a]=str(pp['007'][y][g][a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative population counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load pop data from http://esa.un.org/unpd/wpp/DVD/Files/1_Indicators%20(Standard)/EXCEL_FILES/1_Population/WPP2015_POP_F15_2_ANNUAL_POPULATION_BY_AGE_MALE.XLS\n",
    "wd=pd.read_excel('WPP2015_POP_F15_2_ANNUAL_POPULATION_BY_AGE_MALE.XLS',skiprows=16)\n",
    "wd=wd.drop(['Major area, region, country or area *','Index','Variant','Notes','80+'],axis=1)\n",
    "wd.columns=['Country','Year']+list(np.arange(21)*5)\n",
    "wd=wd.set_index(['Country','Year'])\n",
    "\n",
    "#load pop data from http://esa.un.org/unpd/wpp/DVD/Files/1_Indicators%20(Standard)/EXCEL_FILES/1_Population/WPP2015_POP_F15_2_ANNUAL_POPULATION_BY_AGE_MALE.XLS\n",
    "wf=pd.read_excel('WPP2015_POP_F15_3_ANNUAL_POPULATION_BY_AGE_FEMALE.XLS',skiprows=16)\n",
    "wf=wf.drop(['Major area, region, country or area *','Index','Variant','Notes','80+'],axis=1)\n",
    "wf.columns=['Country','Year']+list(np.arange(21)*5)\n",
    "wf=wf.set_index(['Country','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill missing years and aggregates\n",
    "wd[2]=wd[0]*1/5.0\n",
    "wd[3]=wd[0]*1/5.0\n",
    "wd[4]=wd[0]*1/5.0\n",
    "wd[1]=wd[0]*1/5.0\n",
    "wd[0]=wd[0]*1/5.0\n",
    "wd[95]=wd[95]+wd[100]\n",
    "wd=wd.drop(100,axis=1)\n",
    "\n",
    "#fill missing years and aggregates\n",
    "wf[2]=wf[0]*1/5.0\n",
    "wf[3]=wf[0]*1/5.0\n",
    "wf[4]=wf[0]*1/5.0\n",
    "wf[1]=wf[0]*1/5.0\n",
    "wf[0]=wf[0]*1/5.0\n",
    "wf[95]=wf[95]+wf[100]\n",
    "wf=wf.drop(100,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wdp={}\n",
    "for p in wd.T.iteritems():\n",
    "    try:\n",
    "        country_id=p[0][0]\n",
    "        if str(country_id) not in wdp: wdp[str(country_id)]={}\n",
    "        if p[0][1]>1985: #no mortality data before that\n",
    "            if str(p[0][1]) not in wdp[str(country_id)]:wdp[str(country_id)][str(p[0][1])]={}\n",
    "            g='m'\n",
    "            if g not in wdp[str(country_id)][str(p[0][1])]:wdp[str(country_id)][str(p[0][1])][g]={}\n",
    "            for j in wd.columns:\n",
    "                v=p[1][j]\n",
    "                if np.isnan(p[1][j]):v=0\n",
    "                wdp[str(country_id)][str(p[0][1])][g][str(j)]=str(v*1000.0)\n",
    "    except: pass\n",
    "    \n",
    "for p in wf.T.iteritems():\n",
    "    try:\n",
    "        country_id=p[0][0]\n",
    "        if str(country_id) not in wdp: wdp[str(country_id)]={}\n",
    "        if p[0][1]>1985: #no mortality data before that\n",
    "            if str(p[0][1]) not in wdp[str(country_id)]:wdp[str(country_id)][str(p[0][1])]={}\n",
    "            g='f'\n",
    "            if g not in wdp[str(country_id)][str(p[0][1])]:wdp[str(country_id)][str(p[0][1])][g]={}\n",
    "            for j in wd.columns:\n",
    "                v=p[1][j]\n",
    "                if np.isnan(p[1][j]):v=0\n",
    "                wdp[str(country_id)][str(p[0][1])][g][str(j)]=str(v*1000.0)\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierarchy2={}\n",
    "c={}\n",
    "for country in df.index.get_level_values('Country').unique():\n",
    "    if ccv(cc.loc[country][0]) not in ['Netherlands Antilles',\n",
    "                                       'United Kingdom, England and Wales',\n",
    "                                       'United Kingdom, Scotland',\n",
    "                                       'United Kingdom, Northern Ireland',\n",
    "                                       'Rodrigues']:\n",
    "        \n",
    "        try:\n",
    "            country_id=countries.loc[ccv(cc.loc[country][0])]            \n",
    "            print country_id,ccv(cc.loc[country][0])\n",
    "            c[country_id]=cc.loc[country][0]\n",
    "            \n",
    "            data={}\n",
    "            data3=[]\n",
    "\n",
    "            dk=df.loc[country].drop(['Deaths1','Deaths26'],axis=1)\n",
    "            dk.columns=range(5)+list(np.arange(1,20)*5) \n",
    "\n",
    "            for i in dk.stack().iteritems():\n",
    "                if i[0][2]>1:gender='f'\n",
    "                else: gender='m'\n",
    "                cause=i[0][1].strip()\n",
    "                if cause not in 'AAA':\n",
    "                    key='A'+str(i[0][3])+'C'+str(cause)+'T'+str(i[0][0])\n",
    "                    if key not in data: data[key]={}\n",
    "                    data[key]['a']=i[0][3]\n",
    "                    data[key]['c']=cause\n",
    "                    data[key]['t']=i[0][0]\n",
    "                    data[key]['s']=i[1]\n",
    "                    data[key]['g']=gender\n",
    "                    if cause not in hierarchy2: hierarchy2[cause]={}\n",
    "                    cause2=cause[:3]\n",
    "                    hierarchy2[cause][\"cause2\"]=cause2\n",
    "                    hierarchy2[cause][\"parent\"]=get_parent(cause2)\n",
    "                    hierarchy2[cause][\"group\"]=get_group(cause2)\n",
    "                    data3.append(data[key])\n",
    "                        \n",
    "            file('db/data.json','w').write(json.dumps(data3))  \n",
    "            try:\n",
    "                import zlib\n",
    "                compression = zipfile.ZIP_DEFLATED\n",
    "            except:\n",
    "                compression = zipfile.ZIP_STORED\n",
    "            zf = zipfile.ZipFile('db/'+str(country_id)+'.zip', mode='w')\n",
    "            zf.write('db/data.json','data.json',compress_type=compression)\n",
    "            zf.close()\n",
    "            \n",
    "        except: print 'error',country_id,ccv(cc.loc[country][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file('hierarchy.json','w').write(json.dumps(hierarchy2))  #only do once ever, dont overwrite! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierarchy3={}\n",
    "c={}\n",
    "for country in df.index.get_level_values('Country').unique():\n",
    "    if ccv(cc.loc[country][0]) not in ['Netherlands Antilles',\n",
    "                                       'United Kingdom, England and Wales',\n",
    "                                       'United Kingdom, Scotland',\n",
    "                                       'United Kingdom, Northern Ireland',\n",
    "                                       'Rodrigues']:\n",
    "        \n",
    "        try:\n",
    "            country_id=countries.loc[ccv(cc.loc[country][0])]            \n",
    "            print country_id,ccv(cc.loc[country][0])\n",
    "            c[country_id]=cc.loc[country][0]\n",
    "            \n",
    "            data={}\n",
    "            data3=[]\n",
    "\n",
    "            dk=df.loc[country].drop(['Deaths1','Deaths26'],axis=1)\n",
    "            dk.columns=range(5)+list(np.arange(1,20)*5) \n",
    "\n",
    "            for i in dk.stack().iteritems():\n",
    "                if i[0][2]>1:gender='f'\n",
    "                else: gender='m'\n",
    "                cause=i[0][1].strip()\n",
    "                if cause not in 'AAA':\n",
    "                    cause=get_parent(i[0][1].strip()[:3])\n",
    "                    key='A'+str(i[0][3])+'C'+str(cause)+'T'+str(i[0][0])+'G'+gender\n",
    "                    if key not in data: data[key]={}\n",
    "                    data[key]['a']=i[0][3]\n",
    "                    data[key]['c']=cause\n",
    "                    data[key]['g']=gender\n",
    "                    data[key]['t']=i[0][0]\n",
    "                    if 's' not in data[key]:data[key]['s']=0\n",
    "                    data[key]['s']+=i[1]\n",
    "                    if cause not in hierarchy3: hierarchy3[cause]={}\n",
    "                    cause2=cause\n",
    "                    hierarchy3[cause][\"cause2\"]=cause\n",
    "                    hierarchy3[cause][\"parent\"]=cause\n",
    "                    hierarchy3[cause][\"group\"]=get_group(cause2)\n",
    "            \n",
    "            for key in data:\n",
    "                data3.append(data[key])\n",
    "                        \n",
    "            file('db2/data.json','w').write(json.dumps(data3))  \n",
    "            try:\n",
    "                import zlib\n",
    "                compression = zipfile.ZIP_DEFLATED\n",
    "            except:\n",
    "                compression = zipfile.ZIP_STORED\n",
    "            zf = zipfile.ZipFile('db2/'+str(country_id)+'.zip', mode='w')\n",
    "            zf.write('db2/data.json','data.json',compress_type=compression)\n",
    "            zf.close()\n",
    "            \n",
    "        except: pass#print 'error',country_id,ccv(cc.loc[country][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file('hierarchy2.json','w').write(json.dumps(hierarchy3))  #only do once ever, dont overwrite! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run once!\n",
    "#save country population for which there is modrtality data\n",
    "mdata=['900']\n",
    "\n",
    "for country in df.index.get_level_values('Country').unique():\n",
    "    if ccv(cc.loc[country][0]) not in ['Netherlands Antilles',\n",
    "                                       'United Kingdom, England and Wales',\n",
    "                                       'United Kingdom, Scotland',\n",
    "                                       'United Kingdom, Northern Ireland',\n",
    "                                       'Rodrigues']:\n",
    "        \n",
    "        try:\n",
    "            country_id=countries.loc[ccv(cc.loc[country][0])]            \n",
    "            mdata.append(str(country_id)) #append country id to list of available countries\n",
    "        except: print 'error',country_id,ccv(cc.loc[country][0])\n",
    "\n",
    "for c in wdp.keys():\n",
    "    if c not in mdata:\n",
    "        wdp.pop(c);\n",
    "file('pop.json','w').write(json.dumps(wdp))  #only do once ever, dont overwrite!\n",
    "file('wpop.json','w').write(json.dumps(wdp))  #only do once ever, dont overwrite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1986',\n",
       " '1987',\n",
       " '1993',\n",
       " '1992',\n",
       " '1995',\n",
       " '1994',\n",
       " '1990',\n",
       " '1996',\n",
       " '1988',\n",
       " '1989',\n",
       " '1991']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp['32'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get scaler of world vs. actual data\n",
    "dr=[]\n",
    "for y in range(1990,2005): #years with best overall data availability\n",
    "    yr=str(y)\n",
    "    for g in ['f','m']:\n",
    "        for i in pp['007'][yr][g].keys():\n",
    "            dr.append(float(pp['007'][yr][g][i])/float(wdp['900'][yr][g][i]))\n",
    "wsc=np.array(dr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load df for global data\n",
    "df=load_df(['Frmat','Sex', 'Year', 'Cause','Country'])\n",
    "years=df.loc[1].index.get_level_values('Year').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c={}\n",
    "country_id=900 #world\n",
    "with open(\"db2/data.json\", \"w\") as data3: data3.write(\"\")\n",
    "with open(\"db2/data.json\", \"a\") as data3: \n",
    "    data3.write(\"[\")\n",
    "    for y in range(2000,2014):#years:\n",
    "        print y\n",
    "        for g in [1,2]:\n",
    "            try:\n",
    "                dk=df.loc[g].loc[y].stack().unstack('Country').T.sum().unstack().drop(['Deaths1','Deaths26'],axis=1)\n",
    "                dk.columns=range(5)+list(np.arange(1,20)*5) \n",
    "                data={}\n",
    "                for i in dk.stack().iteritems():\n",
    "                    if g>1:gender='f'\n",
    "                    else: gender='m'\n",
    "                    cause=i[0][0].strip()\n",
    "                    if cause not in 'AAA':\n",
    "                        #if i[1]>0:\n",
    "                            cause=get_parent(i[0][0].strip()[:3])\n",
    "                            key='A'+str(i[0][1])+'C'+str(cause)+'T'+str(y)+'G'+gender\n",
    "                            if key not in data: data[key]={}\n",
    "                            data[key]['a']=i[0][1]\n",
    "                            data[key]['c']=cause\n",
    "                            data[key]['g']=gender\n",
    "                            data[key]['t']=str(y)\n",
    "                            if 's' not in data[key]:data[key]['s']=0\n",
    "                            data[key]['s']+=i[1]/wsc #multiply with global scaler\n",
    "                for key in data:\n",
    "                    data3.write(json.dumps(data[key])+',')    \n",
    "\n",
    "            except: pass#print 'error',country_id,ccv(cc.loc[country][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove last comma character\n",
    "#from here http://stackoverflow.com/questions/1877999/delete-final-line-in-file-via-python\n",
    "with open(\"db2/data.json\", \"r+\") as data3:\n",
    "    #Move the pointer (similar to a cursor in a text editor) to the end of the file. \n",
    "    data3.seek(0, os.SEEK_END)\n",
    "\n",
    "    #This code means the following code skips the very last character in the file - \n",
    "    #i.e. in the case the last line is null we delete the last line \n",
    "    #and the penultimate one\n",
    "    pos = data3.tell() - 1\n",
    "    data3.seek(pos, os.SEEK_SET)\n",
    "    data3.truncate()\n",
    "\n",
    "    data3.close()\n",
    "with open(\"db2/data.json\", \"a\") as data3: data3.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try this, if it freezes, then just zip manually\n",
    "try:\n",
    "    import zlib\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "except:\n",
    "    compression = zipfile.ZIP_STORED\n",
    "zf = zipfile.ZipFile('db2/'+str(country_id)+'.zip', mode='w')\n",
    "zf.write('db2/data.json','data.json',compress_type=compression)\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c={}\n",
    "country_id=900 #world\n",
    "with open(\"db/data.json\", \"w\") as data3: data3.write(\"\")\n",
    "with open(\"db/data.json\", \"a\") as data3: \n",
    "    data3.write(\"[\")\n",
    "    for y in range(2001,2014):#years:\n",
    "        print y\n",
    "        for g in [1,2]:\n",
    "            try:\n",
    "                dk=df.loc[g].loc[y].stack().unstack('Country').T.sum().unstack().drop(['Deaths1','Deaths26'],axis=1)\n",
    "                dk.columns=range(5)+list(np.arange(1,20)*5) \n",
    "                data={}\n",
    "                for i in dk.stack().iteritems():\n",
    "                    if g>1:gender='f'\n",
    "                    else: gender='m'\n",
    "                    cause=i[0][0].strip()\n",
    "                    if cause not in 'AAA':\n",
    "                        #if i[1]>0:\n",
    "                            cause=i[0][0].strip()[:3]\n",
    "                            key='A'+str(i[0][1])+'C'+str(cause)+'T'+str(y)+'G'+gender\n",
    "                            if key not in data: data[key]={}\n",
    "                            data[key]['a']=i[0][1]\n",
    "                            data[key]['c']=cause\n",
    "                            data[key]['g']=gender\n",
    "                            data[key]['t']=str(y)\n",
    "                            if 's' not in data[key]:data[key]['s']=0\n",
    "                            data[key]['s']+=i[1]/wsc #multiply with global scaler\n",
    "                for key in data:\n",
    "                    data3.write(json.dumps(data[key])+',')    \n",
    "\n",
    "            except: pass#print 'error',country_id,ccv(cc.loc[country][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove last comma character\n",
    "#from here http://stackoverflow.com/questions/1877999/delete-final-line-in-file-via-python\n",
    "with open(\"db/data.json\", \"r+\") as data3:\n",
    "    #Move the pointer (similar to a cursor in a text editor) to the end of the file. \n",
    "    data3.seek(0, os.SEEK_END)\n",
    "\n",
    "    #This code means the following code skips the very last character in the file - \n",
    "    #i.e. in the case the last line is null we delete the last line \n",
    "    #and the penultimate one\n",
    "    pos = data3.tell() - 1\n",
    "    data3.seek(pos, os.SEEK_SET)\n",
    "    data3.truncate()\n",
    "\n",
    "    data3.close()\n",
    "with open(\"db/data.json\", \"a\") as data3: data3.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try this, if it freezes, then just zip manually\n",
    "try:\n",
    "    import zlib\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "except:\n",
    "    compression = zipfile.ZIP_STORED\n",
    "zf = zipfile.ZipFile('db/'+str(country_id)+'.zip', mode='w')\n",
    "zf.write('db/data.json','data.json',compress_type=compression)\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pretty country nams, EN+HUN\n",
    "cnames=json.loads(file(\"../szekelyfold lakossag 2/cnames.json\").read())\n",
    "hnames=json.loads(file(\"../szekelyfold lakossag 2/hnames.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need ot run only once\n",
    "def hun(c):\n",
    "    if c=='Antigua and Barbuda': return u'Antigua és Barbuda'\n",
    "    elif c=='Bahamas': return u'Bahamák'\n",
    "    elif c=='British Virgin Islands': return u'Brit Virgin-szigetek'\n",
    "    elif c=='Cayman Islands': return u'Kajmán-szigetek'\n",
    "    elif c=='Dominica': return u'Dominika'\n",
    "    elif c==u'R\\xc3\\xa9union': return u'Réunion'\n",
    "    elif c=='French Guiana': return u'Francia Guyana'\n",
    "    elif c=='Saint Kitts and Nevis': return u'Saint Kitts és Nevis'\n",
    "    elif c=='Saint Vincent and the Grenadines': return u'Szent Vincent és a Grenadine-szigetek'\n",
    "    elif c=='Turks and Caicos Islands': return u'Turks és Caicos-szigetek'\n",
    "    elif c=='U.S. Virgin Islands': return u'U.S. Virgin-szigetek'\n",
    "    elif c=='Saint Pierre and Miquelon': return u'Saint Pierre és Miquelon'\n",
    "    elif c=='World': return u'Egész Világ'\n",
    "    else: return c\n",
    "    \n",
    "for country in df.index.get_level_values('Country').unique():\n",
    "    try:\n",
    "        country_id=countries.loc[ccv(cc.loc[country][0])]    \n",
    "        if str(country_id) not in cnames:\n",
    "            cnames[str(country_id)]=ccv(cc.loc[country][0])\n",
    "        if ccv(cc.loc[country][0]) not in hnames:\n",
    "            print repr(ccv(cc.loc[country][0]))\n",
    "            hnames[ccv(cc.loc[country][0])]=hun(ccv(cc.loc[country][0]))\n",
    "    except:pass\n",
    "    \n",
    "cnames[u'900']=u\"World\"\n",
    "hnames[u'World']=u\"Egész Világ\"\n",
    "file('cnames.json','w').write(json.dumps(cnames))  \n",
    "file('hnames.json','w').write(json.dumps(hnames))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretty country nams, EN+HUN\n",
    "cnames=json.loads(file(\"cnames.json\").read())\n",
    "hnames=json.loads(file(\"hnames.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hc(c):\n",
    "    if c==\"Reunion\": return u'R\\xc3\\xa9union'\n",
    "    if c=='Saint Vincent and Grenadines': return u'Saint Vincent and the Grenadines'\n",
    "    if c=='Serbia and Montenegro, Former': return \"Serbia\"\n",
    "    if c=='United States of America': return \"United States\"\n",
    "    if c=='Virgin Islands (USA)': return 'U.S. Virgin Islands'\n",
    "    if c=='Hong Kong SAR': return 'Hong Kong'\n",
    "    if c=='Republic of Moldova': return 'Moldova'\n",
    "    if c=='Republic of Korea': return 'South Korea'\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only run if you haven't run country data parser\n",
    "#recreate country list\n",
    "c={}\n",
    "for country in df.index.get_level_values('Country').unique():\n",
    "    if ccv(cc.loc[country][0]) not in ['Netherlands Antilles',\n",
    "                                       'United Kingdom, England and Wales',\n",
    "                                       'United Kingdom, Scotland',\n",
    "                                       'United Kingdom, Northern Ireland',\n",
    "                                       'Rodrigues']:\n",
    "            country_id=countries.loc[ccv(cc.loc[country][0])]            \n",
    "            c[country_id]=cc.loc[country][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q={}\n",
    "for i in c:\n",
    "    q[hnames[hc(c[i])]]=i\n",
    "e=[]\n",
    "itera=q.keys()\n",
    "itera.sort(cmp=locale.strcoll)\n",
    "for i in itera:\n",
    "    e.append(str(q[i]))\n",
    "file('countries.json','w').write(json.dumps(['900']+e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q={}\n",
    "for i in c:\n",
    "    q[hc(c[i])]=i\n",
    "e=[]\n",
    "itera=q.keys()\n",
    "itera.sort(cmp=locale.strcoll)\n",
    "for i in itera:\n",
    "    e.append(str(q[i]))\n",
    "file('wcountries.json','w').write(json.dumps(['900']+e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
