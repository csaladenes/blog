{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romania Kendo Stats  \n",
    "#### 25 years of Kendo History in Romania, visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by **[Dénes Csala](//csaladen.es)** | 2019 | MIT License \n",
    "  \n",
    "For any improvement suggestions and spotted processing mistakes drop me a message on [Facebook](//facebook.com/csaladenes).  \n",
    "If you would like to have your country/club data visualized in a similar manner, or any other data visualization and analytics consultancy inquiries contact me at [mail@csaladen.es](mailto:mail@csaladen.es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook guides you through the data cleaning stage for the **Romania Kendo Stats** visualization. This is a multi-stage process, you will need access to the raw data (liaise with Secretary or other member in charge of data the [Romanian Kendo Association](https://www.kendo-romania.ro/)), [Python](https://www.python.org/) and [Excel](https://products.office.com/en-us/excel)  installed. Any Python packages will also be installed on the way, but we recommend using the [Anaconda](https://www.anaconda.com/download/) distribution of _Python 3_. If you would like to edit the visualization part, then you will need [PowerBI Desktop](https://powerbi.microsoft.com/en-us/desktop/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general structure of the repository is the following:  \n",
    " - `/data`\n",
    "   - `/raw`: this where you place the downloaded data from the official data source, sorted by years and competitions, only keep those that have relevant data for matches only\n",
    "   - `/ocr`: this is where the data gets saved after an [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) has been performed - this is necessary for some older files in image format \n",
    "   - `/manual`: this is where manually extracted matches from old image files get placed - they should follow the `2018 CN` format, i.e. all matches in one sheet\n",
    "   - `/export`: this is where we save the dataformatted for loading into the viz\n",
    "   - `/clean`: this is where all the processed, cleaned data ends up - they should follow the `2018 CN` format, i.e. all matches in one sheet\n",
    " - `/scripts`: this is the main code repository for all data processing scripts\n",
    " - `/viz`: this is where the visualization files get saved - they are created using PowerBI and load data from `/data/clean`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and clean members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads and clean the _RKA_ members list. Save as baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T20:55:53.086841Z",
     "start_time": "2018-11-29T20:55:49.243313Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, json\n",
    "import members_loader, matches_loader, clubs_loader, point_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download members data (`Evidenta membrilor.xlsx`) from the official data source, and create a macro-enabled Excel file from the Google Sheet. Then write a simple macro to extract the cell comments from the _Club_ column in order to get info about club _Transfers_. Follow the instructions [here](https://www.extendoffice.com/documents/excel/765-excel-convert-comments-to-cells.html). Save the new file as `Evidenta membrilor.xlsm` in the `/data/manual` folder. Use the `members_loader` module to process this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T20:55:53.097847Z",
     "start_time": "2018-11-29T20:55:53.089844Z"
    }
   },
   "outputs": [],
   "source": [
    "members=members_loader.get_members('../data/manual/Evidenta membrilor.xlsm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members are loaded but a bit messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>231</th>\n",
       "      <th>Nr. EKF</th>\n",
       "      <th>Club</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Numele</th>\n",
       "      <th>Prenumele</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Data naşterii</th>\n",
       "      <th>1 kyu</th>\n",
       "      <th>practică</th>\n",
       "      <th>1 dan</th>\n",
       "      <th>2 dan</th>\n",
       "      <th>3 dan</th>\n",
       "      <th>4 dan</th>\n",
       "      <th>5 dan</th>\n",
       "      <th>6 dan</th>\n",
       "      <th>7 dan</th>\n",
       "      <th>8 dan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activ</td>\n",
       "      <td>RO.00205</td>\n",
       "      <td>TAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abrudan</td>\n",
       "      <td>Dorin-Ștefan</td>\n",
       "      <td>M</td>\n",
       "      <td>1991-12-27</td>\n",
       "      <td>2015-08-08 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inactiv</td>\n",
       "      <td>RO.00083</td>\n",
       "      <td>ICH</td>\n",
       "      <td>Transfer: CRK =&gt; ICH - 2009</td>\n",
       "      <td>Ah-hu</td>\n",
       "      <td>Weizhi Stéphen</td>\n",
       "      <td>M</td>\n",
       "      <td>1980-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>2010-09-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       231   Nr. EKF Club                   Unnamed: 3   Numele  \\\n",
       "0    Activ  RO.00205  TAI                          NaN  Abrudan   \n",
       "1  Inactiv  RO.00083  ICH  Transfer: CRK => ICH - 2009    Ah-hu   \n",
       "\n",
       "        Prenumele Gen Data naşterii                1 kyu practică      1 dan  \\\n",
       "0    Dorin-Ștefan   M    1991-12-27  2015-08-08 00:00:00      NaN 2015-12-19   \n",
       "1  Weizhi Stéphen   M    1980-06-12                  NaN      NaN 2009-08-01   \n",
       "\n",
       "       2 dan 3 dan 4 dan 5 dan 6 dan  7 dan  8 dan  \n",
       "0        NaT   NaT   NaT   NaT   NaT    NaN    NaN  \n",
       "1 2010-09-26   NaT   NaT   NaT   NaT    NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_clean=members_loader.cleaner(members).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_clean.to_csv('../data/clean/members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and clean matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matches are loaded from excel sheets in the `/data` folder, organized by year and competition. We are always looking for match list data,the cleaner the better, the more concentrated the better. While this is not possible all the time, we have several demo import routines. These are stored in the `matches_loader.py` function library. While not all matches have textual data available, these will need to be processed through OCR first. Raw excel data that can be processed right away can be found in the `/data/raw` folder, while the processed ones in `/data/ocr`. We use a separate workbook, `ocr.ipynb` to walk you through the OCR process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches={i:{} for i in range(1993,2019)}\n",
    "competitions={\n",
    "    2018:['CR','CN','SL'],\n",
    "    2017:['CR','CN','SL'],\n",
    "    2016:['CR','CN','SL'],\n",
    "    2015:['CR','CN','SL'],\n",
    "    2014:['CR','CN','SL'],\n",
    "    2013:['CR','CN','SL'],\n",
    "    2012:['CR','CN'],\n",
    "    2011:['CR','CN'],\n",
    "    2010:['CR','CN'],\n",
    "    2009:['CR','CN'],\n",
    "    1998:['CR'],\n",
    "    1997:['CR'],\n",
    "    1993:['CR']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  4  7  8 11 12 15 16 19 20 23 24 27 28 31 32 35 36 39 40 43 44 47\n",
      " 48 51 52 55 56 59 60 63]\n",
      "[ 1  6  9 14 17 22 25 30 33 38 41 46 49 54 57 62]\n",
      "[ 3 12 19 28 35 44 51 60]\n",
      "[ 7 24 39 56]\n",
      "[15 48]\n",
      "[ 0  3  4  7  8 11 12 15 16 19 20 23 24 27 28 31 32 35 36 39 40 43 44 47\n",
      " 48 51 52 55 56 59 60 63]\n",
      "[ 1  6  9 14 17 22 25 30 33 38 41 46 49 54 57 62]\n",
      "[ 3 12 19 28 35 44 51 60]\n",
      "[ 7 24 39 56]\n",
      "[15 48]\n",
      "[ 0  3  4  7  8 11 12 15 16 19 20 23 24 27 28 31 32 35 36 39 40 43 44 47\n",
      " 48 51 52 55 56 59 60 63]\n",
      "[ 1  6  9 14 17 22 25 30 33 38 41 46 49 54 57 62]\n",
      "[ 3 12 19 28 35 44 51 60]\n",
      "[ 7 24 39 56]\n",
      "[15 48]\n"
     ]
    }
   ],
   "source": [
    "for year in competitions:\n",
    "    for competition in competitions[year]:\n",
    "        matches[year][competition]=matches_loader.get_matches(year,competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993, 'CR')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year, competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_type': '../data/raw/2009/CR/2009.04.04 - CR - Budeasa - print.xlsx#IM$pool%nan',\n",
       " 'aka': {'name': 'Antal Róbert', 'point1': nan},\n",
       " 'shiro': {'name': 'Niciev Cristian', 'point1': 'K'},\n",
       " 'outcome': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[2009]['CR'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Standardize names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names in `name_exceptions` get replaced with their right hand side values _before_ processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exceptions={'Atanasovski':'Atanasovski A. (MAC)',\n",
    "                 'Dobrovicescu (SON)':'Dobrovicescu T. (SON)',\n",
    "                 'Ianăș':'Ianăș F.',\n",
    "                 'Crăciun (Tamang) Sujata':'Crăciun S.',\n",
    "                 'Dinu (Ioniță) Claudia-Andreea':'Dinu A.',\n",
    "                 'Arabadjiyski': 'Arabadjiyski A.',\n",
    "                 'Mandia':'Mandia F.',\n",
    "                 'Stanev':'Stanev A.',\n",
    "                 'Mochalov':'Mochalov O.',\n",
    "                 'Sozzi':'Sozzi A.',\n",
    "                 'Crăciunel':'Crăciunel I.',\n",
    "                 'Craciunel':'Crăciunel I.',\n",
    "                 'Sagaev':'Sagaev L.',\n",
    "                 'Buzás':'Búzás C.',\n",
    "                 'Csala':'Csala T.',\n",
    "                 'Dimitrov':'Dimitrov M.',\n",
    "                 'Józsa':'Józsa L.',\n",
    "                 'Creangă':'Creangă A.',\n",
    "                 'Duțescu':'Duțescu M.',                 \n",
    "                 'Furtună':'Furtună G.',\n",
    "                 'Gârbea':'Gârbea I.',\n",
    "                 'Stupu':'Stupu I.',\n",
    "                 'Mahika-Voiconi':'Mahika-Voiconi S.',\n",
    "                 'Mahika':'Mahika-Voiconi S.',\n",
    "                 'Stanciu':'Stanciu F.',\n",
    "                 'Vrânceanu':'Vrânceanu R.',\n",
    "                 'Wolfs':'Wolfs J.',\n",
    "                 'Ducarme':'Ducarme A.',\n",
    "                 'Sbârcea':'Sbârcea B.',\n",
    "                 'Mocian':'Mocian A.',\n",
    "                 'Hatvani':'Hatvani L.',\n",
    "                 'Dusan':'Dusan N.',\n",
    "                 'Borota':'Borota V.',\n",
    "                 'Tsushima':'Tsushima K.',\n",
    "                 'Tráser':'Tráser T.',\n",
    "                 'Colțea':'Colțea A.',\n",
    "                 'Brîcov':'Brîcov A.',\n",
    "                 'Yamamoto':'Yamamoto M.',\n",
    "                 'Crăciun':'Crăciun D.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names in `name_equals` get replaced with their right hand side values _after_ processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_equals={'Chirea M.':'Chirea A.',\n",
    "            'Ghinet C.':'Ghineț C.',\n",
    "            'Anghelescu A.':'Anghelescu M.',\n",
    "            'Domnița M.':'Domniță M.',\n",
    "            'Bejgu N.':'Beygu N.',\n",
    "            'Canceu A.':'Canceu Ad.',\n",
    "            'Dinu C.':'Dinu A.',\n",
    "            'Grapa D.':'Grapă D.',\n",
    "            'Cristea C.':'Cristea Că.',\n",
    "            'Cismas O.':'Cismaș O.',\n",
    "            'Garbea I.':'Gârbea I.',\n",
    "            'Ah-hu W.':'Ah-hu S.',\n",
    "            'Horvát M.':'Horváth M.',\n",
    "            'Ionita A.':'Ioniță A.',\n",
    "            'Medvedschi I.':'Medvețchi I.',\n",
    "            'Mahika S.':'Mahika-Voiconi S.',\n",
    "            'Mate L.':'Máté L.',\n",
    "            'Hentea L.':'Hentea A.',\n",
    "            'Stupu I.':'Stupu A.',\n",
    "            'Ah-Hu S.':'Ah-hu S.',\n",
    "            'Alexa I.':'Alexa A.',\n",
    "            'Albert V.':'Albert J.',\n",
    "            'Angelescu M.':'Angelescu M.',\n",
    "            'Apostu D.':'Apostu T.',\n",
    "            'Brâcov A.':'Brîcov A.',\n",
    "            'Zaporojan R.':'Zaporojan O.',\n",
    "            'Vasile C.':'Vasile I.',\n",
    "            'Tudor-Duicu C.':'Tudor D.',\n",
    "            'Țarălungă D.':'Țarălungă A.',\n",
    "            'Sandu M.':'Sandu Mar.',\n",
    "            'Radulescu A.':'Rădulescu A.',\n",
    "            'Péter C.':'Péter Cso.',\n",
    "            'Movatz E.':'Movatz V.',\n",
    "            'Molinger B.':'Molinger P.',\n",
    "            'Mitelea C.':'Mițelea C.',\n",
    "            'Macavei I.':'Macaveiu I.',\n",
    "            'Luca T.':'Luca Tr.',\n",
    "            'Leca L.':'Leca F.',\n",
    "            'Gutu E.':'Guțu E.',\n",
    "            'Mehelean L.':'Mahalean L.',\n",
    "            'Catoriu D.':'Cantoriu D.',\n",
    "            'Călina A.':'Călina C.',\n",
    "            'Buzás C.':'Búzás C.',\n",
    "            'Korenshi E.':'Korenschi E.',\n",
    "            'Pleșa R.':'Pleșea R.',\n",
    "            'Galos A.':'Galoș A.',\n",
    "            'Győrfi G.':'Györfi G.',\n",
    "            'Győrfi S.':'Györfi S.',\n",
    "            'Ghineț G.':'Ghineț C.',\n",
    "            'Hostina E.':'Hoștină E.', \n",
    "            'Hostină E.':'Hoștină E.', \n",
    "            'Ianăs F.':'Ianăș F.',\n",
    "            'Ianas F.':'Ianăș F.',\n",
    "            'Taralunga D.':'Țarălungă D.',\n",
    "            'Lacatus M.':'Lăcătuș M.',\n",
    "            'Máthé L.':'Máté L.',\n",
    "            'Burinaru A.':'Burinaru Al.',\n",
    "            'Nastase M.':'Năstase E.',\n",
    "            'Oprisan A.':'Oprișan A.',\n",
    "            'Pârlea A.':'Pîrlea A.',\n",
    "            'Sabau D.':'Sabău D.',\n",
    "            'Spriu C.':'Spiru C.',\n",
    "            'Bíró S.':'Biró S.',\n",
    "            'Stănculascu C.':'Stănculescu C.',\n",
    "            'Vrânceanu M.': 'Vrânceanu L.',\n",
    "            'Wasicek V.':'Wasicheck W.',\n",
    "            'Wasicsec W.':'Wasicheck W.',\n",
    "            'Wasicsek W.':'Wasicheck W.',\n",
    "            'Zolfoghari A.':'Zolfaghari A.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names in `name_doubles` handle situation where the default name abbreviation might lead to duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_doubles={\n",
    "        'Cristea Cristina':'Cristea Cr.', \n",
    "        'Cristea Călin-Ștefan':'Cristea Că.',\n",
    "        'Sandu Marius-Cristian':'Sandu Mar.', \n",
    "        'Sandu Matei-Serban':'Sandu Mat.',\n",
    "        'Georgescu Andrei':'Georgescu An.', \n",
    "        'Georgescu Alexandra':'Georgescu Al.',\n",
    "        'Péter Csongor':'Péter Cso.', \n",
    "        'Péter Csanád':'Péter Csa.',\n",
    "        'Luca Mihnea':'Luca Mihn.', \n",
    "        'Luca Mihai-Cătălin':'Luca Miha.',\n",
    "        'Luca':'Luca Miha.',\n",
    "        'Luca M':'Luca Miha.',\n",
    "        'Luca M.':'Luca Miha.',\n",
    "        'Luca Mihai':'Luca Miha.',\n",
    "        'Luca Traian-Dan':'Luca Tr.', \n",
    "        'Luca Tudor':'Luca Tu.',\n",
    "        'Canceu Anamaria':'Canceu An.', \n",
    "        'Canceu Adriana-Maria':'Canceu Ad.',\n",
    "        'Cioată Daniel-Mihai':'Cioată M.', \n",
    "        'Cioată Dragoș':'Cioată D.',\n",
    "        'Burinaru Alexandra':'Burinaru Al.', \n",
    "        'Burinaru Andreea':'Burinaru An.',\n",
    "        'Dudaș Francisc Andrei':'Dudaș F.', \n",
    "        'Dudaș Francisc':'Dudaș F.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Romanian characters, define name cleaner function to get _Name IDs_. Name ID are unique competitor names in the form of: _Surname, First letter of Name_. If the First Letter of Name leads to a non-unique ID, the second letter is taken, and so forth, until a unique ID is found. It gets contructed as follows:\n",
    " 1. If name in doubles return the solution directly\n",
    " 2. Normalize characters\n",
    " 3. If name is in exceptions, clean\n",
    " 4. Replace any double spaces, then split at _(_ (to split away club, if embedded in the name)\n",
    " 5. Split into Surname and Name, store in `rnames`\n",
    " 6. Store _Surname N._ in `sname`\n",
    " 7. If `sname` is in equals, clean\n",
    " 8. Retrun `sname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_norm={'ţ':'ț','ş':'ș','Ş':'Ș'}\n",
    "def name_cleaner(name):\n",
    "    name=str(name)\n",
    "    if name in name_doubles:\n",
    "        return name_doubles[name]\n",
    "    else:\n",
    "        for letter in letter_norm:\n",
    "            name=name.replace(letter,letter_norm[letter])\n",
    "        if name in name_exceptions:\n",
    "            name=name_exceptions[name]\n",
    "        nc=name.replace('  ',' ').split('(')    \n",
    "            \n",
    "        rname=nc[0].strip()\n",
    "        rnames=rname.split(' ')\n",
    "        sname=rnames[0]+' '+rnames[1][0]+'.'\n",
    "        if sname in name_equals:\n",
    "            sname=name_equals[sname]\n",
    "        if sname in name_doubles:\n",
    "            print(name,sname)\n",
    "    return sname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names equalling any string in `redflags_names` get thrown out of the final dataset.  \n",
    "Names containing any string in `redflags_names2` get thrown out of the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "redflags_names=['-','—','—',np.nan,'. ()','— ','- -.','- -. (-)','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','R','S',\n",
    "                'Kashi','Sankon','București','Victorii:','Sakura','Taiken','Ikada','Sonkei','CRK','Museido',\n",
    "                'Ichimon','Bushi Tokukai 1','Competitori – Shiai-sha','Echipa - roşu','Numele şi prenumele',\n",
    "                'Victorii:','Victorii: 0','Victorii: 1','Victorii: 2','Victorii: 3','Victorii: 4',\n",
    "                'Victorii: 5','?','Kyobukan','2/5','2/6','3/8','Finala','Kyobukan (0/0/0)','―',\n",
    "                '(clasament final după meci de baraj)','CRK (Bucuresti)','Kaybukan','Isshin (Cluj)',\n",
    "                'Ikada (Bucureşti)','Kyobukan (Braşov)','Puncte:','KASHI','Budoshin','Isshin',\n",
    "                '— (—)','4. B.','4. Baraj: Stupu M - Hostina','4. Baraj: Moise KM - Korenschi M',\n",
    "               'Bushi Tokukai (2/8/17)','CRK 2 (1/6/14)', 'CRK 2','CRK 1','Loc I.:','Loc',\n",
    "               'Bushi Tokukai 2 (M Ciuc)','Echipa suport']\n",
    "redflags_names2=['Bushi Tokukai','Eliminatoriu','finala','Finala','Fianala','Ikada','Ichimon','Pool',\n",
    "                'Locul ','Lotul ','Loc ','Grupa ','Isshin','Meciul ','Victorii:','L1','1','2','3','4','5','6','7','8','9','0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check is name is not in redflags. Ignore these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_ok(name):\n",
    "    name=str(name)\n",
    "    if name=='nan': return False\n",
    "    if name not in redflags_names:\n",
    "        if np.array([i not in name for i in redflags_names2]).all():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all names for standardization. Create 3 variables:  \n",
    "1. `all_players`: forward relationship: unclean name -> cleaned name\n",
    "2. `all_players_r`: reverse relationship\n",
    "3. `all_players_unsorted`: unique set of all names processed \n",
    "\n",
    "Process both competitor and shinpan names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players={}\n",
    "all_players_r={}\n",
    "all_players_unsorted=set()\n",
    "for year in matches:\n",
    "    for competition in matches[year]:\n",
    "        for match in matches[year][competition]:\n",
    "            for color in ['aka','shiro']:\n",
    "                name=match[color]['name']\n",
    "                all_players_unsorted.add(name)\n",
    "                if name_ok(name):\n",
    "                    name=name_cleaner(name)\n",
    "                    rname=match[color]['name']\n",
    "                    if rname not in all_players_r:all_players_r[rname]=name\n",
    "                    if name not in all_players: all_players[name]={}\n",
    "                    if year not in all_players[name]:all_players[name][year]={'names':set()}\n",
    "                    all_players[name][year]['names'].add(rname)\n",
    "            if 'shinpan' in match:\n",
    "                for color in ['fukushin1','shushin','fukushin2']:\n",
    "                    aka=match['aka']['name']\n",
    "                    shiro=match['shiro']['name']\n",
    "                    if (name_ok(aka)) and\\\n",
    "                       (name_ok(shiro)) and\\\n",
    "                       (name_cleaner(aka) in all_players) and\\\n",
    "                       (name_cleaner(shiro) in all_players):\n",
    "                        rname=match['shinpan'][color]\n",
    "                        all_players_unsorted.add(rname)\n",
    "                        if name_ok(rname):\n",
    "                            name=name_cleaner(rname)\n",
    "                            if rname not in all_players_r:all_players_r[rname]=name\n",
    "                            if name not in all_players: all_players[name]={}\n",
    "                            if year not in all_players[name]:all_players[name][year]={'names':set()}\n",
    "                            all_players[name][year]['names'].add(rname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link procesed to names in `members`. The `name_linker` dictionary contains Name IDs (short names) as keys and sets of long names as values. Ideally, this set should contain only one element, so that the mapping in unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_linker={}\n",
    "for i in members_clean.index:\n",
    "    name=members_clean.loc[i]['name']\n",
    "    try:\n",
    "        cname=name_cleaner(name)\n",
    "    except:\n",
    "        print(name)\n",
    "    if cname not in name_linker:name_linker[cname]=set()\n",
    "    name_linker[cname].add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the opposite mapping in `names_abbr`: long->short. Create exceptions for duplicate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dudaș F. {'Dudaș Francisc', 'Dudaș Francisc Andrei'}\n"
     ]
    }
   ],
   "source": [
    "names_abbr={}\n",
    "for name in name_linker:\n",
    "    if len(name_linker[name])>1:\n",
    "        #only for dev to create exceptions for duplicate person names.\n",
    "        print(name,name_linker[name])\n",
    "    for i in name_linker[name]:\n",
    "        names_abbr[i]=name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save club mappings by short name, by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_abbr_list=[]\n",
    "name_abbr2long={}\n",
    "name_abbr2club={}\n",
    "for i in members_clean.index:\n",
    "    name=members_clean.loc[i]['name']\n",
    "    club=members_clean.loc[i]['club']\n",
    "    year=members_clean.loc[i]['year']\n",
    "    names_abbr_list.append(names_abbr[name])\n",
    "    name_abbr2long[names_abbr[name]]=name\n",
    "    if names_abbr[name] not in name_abbr2club:name_abbr2club[names_abbr[name]]={}\n",
    "    name_abbr2club[names_abbr[name]][year]=club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add short names to `members_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_clean['name_abbr']=names_abbr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some names appear in the short form, we need to add them manually to the long list. We parse through all forms in which the name appears, and choose the longest. We call this the inferred name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_players:\n",
    "    if name not in name_abbr2long:\n",
    "        #infer using longest available name\n",
    "        names={len(j):j  for i in all_players[name] for j in all_players[name][i]['names']}\n",
    "        if len(names)>0:\n",
    "            inferred_name=names[max(names.keys())]\n",
    "            if '(' in inferred_name:\n",
    "                inferred_name=inferred_name[:inferred_name.find('(')-1]\n",
    "            name_abbr2long[name]=inferred_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Infer clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer clubs from name if club is part of name in the competition. Club names in `redflags_clubs` get ignored. Clubs in `club_equals` get replaced _after_ processing. The convention is to have 3 letter all-caps club names for Romanian clubs, 3 letter club names followed by a / and a two letter country code for foreign clubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "redflags_clubs=['','N/A','RO1','RO2']\n",
    "club_equals={'MLD':'MOL/Md',\n",
    "             'MOL':'MOL/Md',\n",
    "             'IKD':'IKA',\n",
    "             'HUN':'HUN/Hu',\n",
    "             'BUL':'BUL/Bg',\n",
    "             'TUR':'TUR/Tr',\n",
    "             'MAC':'MAC/Mc',\n",
    "             'MNE':'MNE/Mn',\n",
    "             'SRB':'SRB/Sr',\n",
    "             'ITA':'ITA/It',\n",
    "             'ISS':'ISH',\n",
    "             'Musso, Bg':'MUS/Bg',\n",
    "             'Makoto, Sr':'MAK/Sr',\n",
    "             'Szeged, Hu':'SZE/Hu'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach clubs to all_players who have it in their competition name data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_players:\n",
    "    #if we dont already know the club for this year from the members register\n",
    "    if name not in name_abbr2club:    \n",
    "        for year in all_players[name]:\n",
    "            for name_form in all_players[name][year]['names']:\n",
    "                if '(' in name_form:\n",
    "                    club=name_form.split('(')[1].strip()[:-1]\n",
    "                    if club not in redflags_clubs:\n",
    "                        if name not in name_abbr2club:name_abbr2club[name]={}\n",
    "                        name_abbr2club[name][year]=club\n",
    "    else:\n",
    "        for year in all_players[name]:\n",
    "            #ese if no club info for particular year\n",
    "            if year not in name_abbr2club[name]:\n",
    "                for name_form in all_players[name][year]['names']:\n",
    "                    if '(' in name_form:\n",
    "                        club=name_form.split('(')[1].strip()[:-1]\n",
    "                        if club not in redflags_clubs:\n",
    "                            name_abbr2club[name][year]=club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize club names and long names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_abbr2club:\n",
    "    for year in name_abbr2club[name]:\n",
    "        if name_abbr2club[name][year] in club_equals: \n",
    "            name_abbr2club[name][year]=club_equals[name_abbr2club[name][year]]\n",
    "for name in name_abbr2long:\n",
    "    name_abbr2long[name]=name_abbr2long[name].replace('  ',' ').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If club still not found, fill the gaps between years. Forward fill first, then backward fill, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_club_needed=set()\n",
    "for name in all_players:\n",
    "    if name in name_abbr2club:\n",
    "        years=np.sort(list(all_players[name].keys()))\n",
    "        minyear1=min(years)\n",
    "        maxyear1=max(years)\n",
    "        minyear2=min(name_abbr2club[name].keys())\n",
    "        maxyear2=min(name_abbr2club[name].keys())\n",
    "                    \n",
    "        if len(years)>1:\n",
    "            for year in range(min(minyear1,minyear2),max(maxyear1,maxyear2)+1):\n",
    "                if year not in name_abbr2club[name]:\n",
    "                    #get club from previous year\n",
    "                    for y in range(years[0],year):\n",
    "                        if y in name_abbr2club[name]:\n",
    "                            name_abbr2club[name][year]=str(name_abbr2club[name][y])\n",
    "                            break\n",
    "                if year not in name_abbr2club[name]:\n",
    "                    #if still not found, get club from next year\n",
    "                    for y in np.arange(years[-1],year,-1):\n",
    "                        if y in name_abbr2club[name]:\n",
    "                            name_abbr2club[name][year]=str(name_abbr2club[name][y])\n",
    "                            break\n",
    "                if year not in name_abbr2club[name]:\n",
    "                    #if still not found, get first known year\n",
    "                    if year<minyear2:\n",
    "                        name_abbr2club[name][year]=str(name_abbr2club[name][minyear2])\n",
    "                    else:\n",
    "                        name_abbr2club[name][year]=str(name_abbr2club[name][maxyear2])\n",
    "            #now interpolate years with missing data\n",
    "            #for year in name_abbr2club[name]:\n",
    "    else:\n",
    "        manual_club_needed.add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extracted what was possible from the data. Now we do a save of short name to long name and cllub mappings (by year). We then edit this file manually, if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Manual club and long name overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_name_needed=set()\n",
    "#check if we dont have first name information, then flag for manual additions\n",
    "for name in name_abbr2long:\n",
    "    names=name_abbr2long[name].split(' ')\n",
    "    if len(names)<2:\n",
    "        manual_name_needed.add(name)\n",
    "    elif len(names[1])<3:\n",
    "        manual_name_needed.add(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data_override=pd.read_excel('../data/manual/members_manual.xlsx').set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data_needed=[]\n",
    "for i in manual_name_needed.union(manual_club_needed):\n",
    "    if i not in list(manual_data_override.index):\n",
    "        dummy={'name':i,'long_name':'','club':''}\n",
    "        if i in name_abbr2club:\n",
    "            dummy['club']=name_abbr2club[name][max(list(name_abbr2club[name].keys()))]\n",
    "        if i in manual_club_needed:\n",
    "            if i in name_abbr2long:\n",
    "                dummy['long_name']=name_abbr2long[i]\n",
    "        manual_data_needed.append(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(manual_data_needed).set_index('name')\n",
    "df=pd.concat([manual_data_override,df]).drop_duplicates().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../data/manual/members_manual.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend with manual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['long_name'].replace('',np.nan).dropna().index:\n",
    "    name_abbr2long[i]=df.loc[i]['long_name']\n",
    "    all_players_r[name_abbr2long[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_club_needed=set()\n",
    "for name in all_players:\n",
    "    years=np.sort(list(all_players[name].keys()))\n",
    "    minyear=min(years)\n",
    "    maxyear=max(years)\n",
    "    for year in range(minyear,maxyear+1):\n",
    "        if name not in name_abbr2club:name_abbr2club[name]={}\n",
    "        if year not in name_abbr2club[name]:\n",
    "            if name in df['club'].replace('',np.nan).dropna().index:\n",
    "                name_abbr2club[name][year]=df.loc[name]['club']\n",
    "            else:\n",
    "                name_abbr2club[name][year]='XXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update members  \n",
    "Extend members data with data mined from matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create club cleaner function. Split club from country by /."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def club_cleaner(club,country='RO'):\n",
    "    if club in club_equals:\n",
    "        club=club_equals[club]\n",
    "    if str(club)=='nan':\n",
    "        club='XXX'\n",
    "    if '/' in club:\n",
    "        return club.split('/')[0],club.split('/')[1].upper()\n",
    "    else:\n",
    "        return club,country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create club long name translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_clubs={'ARA':'Arashi', 'ACKIJ':'Official', 'BDS':'Budoshin', 'BSD':'Bushido', 'BTK':'Bushi Tokukai', 'BG':'Bulgaria',\n",
    "              'CDO':'Coroana de Oțel', 'CRK':'Clubul Român de Kendo', 'HAR':'Hargita', \n",
    "              'ICH':'Ichimon', 'IKA':'Ikada','ISH':'Ishhin', 'IT':'Italy','HU':'Hungary',\n",
    "              'KAS':'Kashi', 'KNS':'Kenshin', 'KYO':'Kyobukan', 'MC':'Macedonia',\n",
    "              'SR':'Serbia', 'MN':'Montenegro', 'MD':'Moldova', 'MUS':'Museido', \n",
    "               'RON':'Ronin-do', 'SAK':'Sakura', 'SAM':'Sam-sho','SAN':'Sankon', 'SBK':'Sobukan',\n",
    "               'SON':'Sonkei', 'SR':'Serbia','BE':'Belgium', 'TAI':'Taiken', 'TR':'Turkey', 'XXX':'Unknown',\n",
    "               'YUK':'Yu-kai','KAY':'Kaybukan'}\n",
    "def pretty_club(club, country):\n",
    "    if country!='RO':\n",
    "        return pretty_clubs[country]\n",
    "    else: return pretty_clubs[club]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend members with unregistered members. Either inactive, or from abroad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregistered_members=[]\n",
    "for name in all_players:\n",
    "    if name not in set(members_clean['name_abbr'].values):\n",
    "        years=np.sort(list(name_abbr2club[name].keys()))\n",
    "        for year in range(min(years),max(years)+1):\n",
    "            if year in all_players[name]:\n",
    "                iyear=year\n",
    "            else:\n",
    "                iyear=max(years)\n",
    "            club,country=club_cleaner(name_abbr2club[name][year])\n",
    "            if country=='RO':\n",
    "                activ='Inactiv'\n",
    "                dan=''#dan=0\n",
    "            else:\n",
    "                activ='AS'\n",
    "                dan=''\n",
    "            unregistered_members.append({'name':name_abbr2long[name],'name_abbr':name,\n",
    "                    'club':club,'active':activ,'year':year,'dan':dan,'country':country,\n",
    "                    'pretty_club':pretty_club(club,country)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_clean['country']='RO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "members_updated=pd.concat([members_clean,pd.DataFrame(unregistered_members)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs=[]\n",
    "pclubs=[]\n",
    "countries=[]\n",
    "for i in members_updated.index:\n",
    "    club=members_updated.loc[i]['club']\n",
    "    country=members_updated.loc[i]['country']\n",
    "    cc=club_cleaner(club,country)\n",
    "    clubs.append(cc[0])\n",
    "    pclubs.append(pretty_club(cc[0],cc[1]))\n",
    "    countries.append(cc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_updated['club']=clubs\n",
    "members_updated['pretty_club']=pclubs\n",
    "members_updated['country']=countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend 0 dan down to starting year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993 CR\n",
      "1997 CR\n",
      "1998 CR\n",
      "2009 CR\n",
      "2009 CN\n",
      "2010 CR\n",
      "2010 CN\n",
      "2011 CR\n",
      "2011 CN\n",
      "2012 CR\n",
      "2012 CN\n",
      "2013 CR\n",
      "2013 CN\n",
      "2013 SL\n",
      "2014 CR\n",
      "2014 CN\n",
      "2014 SL\n",
      "2015 CR\n",
      "2015 CN\n",
      "2015 SL\n",
      "2016 CR\n",
      "2016 CN\n",
      "2016 SL\n",
      "2017 CR\n",
      "2017 CN\n",
      "2017 SL\n",
      "2018 CR\n",
      "2018 CN\n",
      "2018 SL\n"
     ]
    }
   ],
   "source": [
    "members_mu_dan_extensions=[]\n",
    "members_by_name=members_updated.set_index(['name_abbr'])\n",
    "for year in matches:\n",
    "    members_by_year=members_updated.set_index(['year']).loc[year]\n",
    "    for competition in matches[year]:\n",
    "        print(year,competition)\n",
    "        for k in matches[year][competition]:\n",
    "            aka=k['aka']['name']\n",
    "            shiro=k['shiro']['name']\n",
    "            if (name_ok(aka)) and\\\n",
    "               (name_ok(shiro)) and\\\n",
    "               (name_cleaner(aka) in all_players) and\\\n",
    "               (name_cleaner(shiro) in all_players):\n",
    "                for a in ['aka','shiro']:\n",
    "                    for h in k[a]:\n",
    "                        if h=='name':\n",
    "                            name=k[a][h]\n",
    "                            rname=all_players_r[name]\n",
    "                            if rname in list(members_by_name.index):\n",
    "                                if rname not in members_by_year['name_abbr'].values:\n",
    "                                    dummy=members_by_name.loc[[rname]]\n",
    "                                    minyear=min(dummy['year'])\n",
    "                                    maxyear=max(dummy['year'])\n",
    "                                    if year>maxyear:\n",
    "                                        dummy=dummy[dummy['year']==maxyear]\n",
    "                                        yeardiff=min(dummy['year'])-year\n",
    "                                    else:\n",
    "                                        dummy=dummy[dummy['year']==minyear]\n",
    "                                        yeardiff=year-max(dummy['year'])\n",
    "                                    dummy=dummy.reset_index()\n",
    "                                    dummy['year']=year\n",
    "                                    dummy['age']=dummy['age']+yeardiff\n",
    "                                    members_mu_dan_extensions.append(dummy)\n",
    "                            #if only appears in competition in one year, then not in members table\n",
    "                            else:\n",
    "                                print(rname,year)\n",
    "                                #fix in unregistered_members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "members_mu_dan_extensions=pd.concat(members_mu_dan_extensions)\n",
    "members_updated=pd.concat([members_updated,members_mu_dan_extensions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix unknwown genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mf_data_override=pd.read_excel('../data/manual/members_mf_manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mf_data_needed=members_updated[(members_updated['gen']!='M')&(members_updated['gen']!='F')][['name_abbr','name']]\\\n",
    "        .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=manual_mf_data_needed.merge(manual_mf_data_override[['name_abbr','gen']],'outer').drop_duplicates()\n",
    "df.to_excel('../data/manual/members_mf_manual.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update members with manual gender data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_updated=members_updated.reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens=[]\n",
    "for i in members_updated.index:\n",
    "    name=members_updated.loc[i]['name_abbr']\n",
    "    if name in list(df.index):\n",
    "        gens.append(df.loc[name])\n",
    "    else:\n",
    "        gens.append(members_updated.loc[i]['gen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_updated['gen']=gens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `/data/export`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_updated.to_csv('../data/export/members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Update matches  \n",
    "Update and save cleaned match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "redflags_points=['Puncte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if outcome was encho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_cleaner(outcome):\n",
    "    if outcome=='E': return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check who won, by how many points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_from_points(aka,shiro):\n",
    "    if aka==shiro: return 'X',0\n",
    "    elif aka>shiro: return 'A',str(aka-shiro)\n",
    "    else: return 'S',str(shiro-aka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create master match variable. Connect this to the viz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993 CR\n",
      "1997 CR\n",
      "1998 CR\n",
      "2009 CR\n",
      "2009 CN\n",
      "2010 CR\n",
      "2010 CN\n",
      "2011 CR\n",
      "2011 CN\n",
      "2012 CR\n",
      "2012 CN\n",
      "2013 CR\n",
      "2013 CN\n",
      "2013 SL\n",
      "2014 CR\n",
      "2014 CN\n",
      "2014 SL\n",
      "2015 CR\n",
      "2015 CN\n",
      "2015 SL\n",
      "2016 CR\n",
      "2016 CN\n",
      "2016 SL\n",
      "2017 CR\n",
      "2017 CN\n",
      "2017 SL\n",
      "2018 CR\n",
      "2018 CN\n",
      "2018 SL\n"
     ]
    }
   ],
   "source": [
    "master_matches=[]\n",
    "for year in matches:\n",
    "    members_by_year=members_updated.set_index(['year']).loc[year].drop_duplicates()\n",
    "    for competition in matches[year]:\n",
    "        print(year,competition)\n",
    "        for k in matches[year][competition]:\n",
    "            good=True\n",
    "            match={'year':year,'competition':competition}\n",
    "            match['match_category'],match['match_teams'],match['match_phase']=point_utils.match_cleaner(year,k['match_type'])\n",
    "            if 'shinpan' in k:\n",
    "                for color in ['fukushin1','shushin','fukushin2']:\n",
    "                    if color in k['shinpan']:\n",
    "                        if k['shinpan'][color] in all_players_r:\n",
    "                            #normalize shinpan names\n",
    "                            match[color]=name_abbr2long[all_players_r[k['shinpan'][color]]]\n",
    "            aka=k['aka']['name']\n",
    "            shiro=k['shiro']['name']\n",
    "            if (name_ok(aka)) and\\\n",
    "               (name_ok(shiro)) and\\\n",
    "               (name_cleaner(aka) in all_players) and\\\n",
    "               (name_cleaner(shiro) in all_players):\n",
    "                for a in ['aka','shiro']:\n",
    "                    points=''\n",
    "                    for h in k[a]:\n",
    "                        if h=='name':\n",
    "                            name=k[a][h]\n",
    "                            #normalize competitor names\n",
    "                            rname=all_players_r[name]\n",
    "                            df=members_by_year[members_by_year['name_abbr']==rname]\n",
    "                            match[a+' name']=name_abbr2long[rname]\n",
    "                        else:\n",
    "                            point=k[a][h]\n",
    "                            if str(point)=='nan': point=''\n",
    "                            points=points+point\n",
    "                    for redflag in redflags_points:\n",
    "                        if redflag in points:\n",
    "                            good=False\n",
    "                    if good:\n",
    "                        match[a+' point1'],match[a+' point2'],match[a+' points'],\\\n",
    "                                match[a+' hansoku'],match['encho']=point_utils.points_cleaner(points)\n",
    "            else:\n",
    "                good=False                \n",
    "            if good:\n",
    "                if 'outcome' in k:\n",
    "                    match['encho']=outcome_cleaner(k['outcome'])\n",
    "                else: \n",
    "                    match['encho']=False\n",
    "                match['winner'],match['difference']=outcome_from_points(match['aka points'],match['shiro points'])\n",
    "\n",
    "                master_matches.append(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up matches for pretty display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(master_matches).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aka hansoku']=data['aka hansoku'].replace(0,'').replace(1,'Δ')\n",
    "data['shiro hansoku']=data['shiro hansoku'].replace(0,'').replace(1,'Δ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/export/matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "aka=data[[i for i in data.columns if 'shiro ' not in i]]\n",
    "aka.columns=[i.replace('aka ','') for i in aka.columns]\n",
    "aka['color']='aka'\n",
    "aka['opponent']=data['shiro name']\n",
    "aka=aka.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "shiro=data[[i for i in data.columns if 'aka ' not in i]]\n",
    "shiro.columns=[i.replace('shiro ','') for i in shiro.columns]\n",
    "shiro['color']='shiro'\n",
    "shiro['opponent']=data['aka name']\n",
    "shiro=shiro.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "extended_matches=pd.concat([aka,shiro],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_matches.to_csv('../data/export/extended_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data by points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\pandas\\core\\frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "p1=extended_matches[[i for i in extended_matches.columns if i!='point2']]\n",
    "p2=extended_matches[[i for i in extended_matches.columns if i!='point1']]\n",
    "p1.rename(columns={'point1':'point'}, inplace=True)\n",
    "p2.rename(columns={'point2':'point'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_points=pd.concat([p1,p2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_points.to_csv('../data/export/extended_points.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save shinpan data - most comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csala\\AppData\\Local\\Continuum\\anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "shu=extended_points[[i for i in extended_points.columns if 'fukushin' not in i]]\n",
    "shu.columns=[i.replace('shushin','shinpan') for i in shu.columns]\n",
    "fk1=extended_points[[i for i in extended_points.columns if 'shushin' not in i and 'fukushin2' not in i]]\n",
    "fk1.columns=[i.replace('fukushin1','shinpan') for i in fk1.columns]\n",
    "fk2=extended_points[[i for i in extended_points.columns if 'shushin' not in i and 'fukushin1' not in i]]\n",
    "fk2.columns=[i.replace('fukushin2','shinpan') for i in fk2.columns]\n",
    "extended_shinpan=pd.concat([shu,fk1,fk2],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_shinpan.to_csv('../data/export/extended_shinpan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
